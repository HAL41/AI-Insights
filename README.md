# AI Insights #3 - July 2025 // ÄŒervenec 2025
*ÄŒeskÃ¡ verze nÃ¡sleduje // Czech version below*

---

# AI Insights #3 â€“ July 2025
Just making it in before July wraps up! Weâ€™re back with another edition of AI Insights. Our goal remains the same: to be your guide through the noise. We focus on the stories that matter most, not just whatâ€™s happening in AI but why it matters and where it might be headed. By connecting the dots and looking beyond the headlines, we aim to offer perspective thatâ€™s clear, relevant, and grounded in the real-world impact these developments have on our work, our industries, and our daily lives.

As we continue to shape AI Insights into a resource thatâ€™s truly valuable for you, your perspective is our most important guide. Whatâ€™s working for you? Whatâ€™s missing? Are you enjoying these deep dives, or would you prefer more quick-hit updates and practical examples? Every piece of feedback helps us refine our approach and ensure weâ€™re delivering content that sparks new ideas and keeps you informed. Please donâ€™t be shy - weâ€™d love to hear from you.

## The New Age of Propaganda
Think about the news you see every day. Whether it's on TV, in a newspaper, or online, the stories are often shaped by the people who own the media company. For decades, weâ€™ve known that a few powerful sources can control the narrative, deciding which stories get told and which get ignored. This creates an "echo chamber," where we mostly hear one side of the story, making it harder to find different viewpoints.

Now, imagine that instead of a TV channel, the main source of information for everyoneâ€”your kids, your students, your coworkersâ€”is a single AI chatbot. There's no channel to switch for a different perspective. Every answer is pre-approved by the system. Building an alternative isn't just difficult; it's nearly impossible unless you're a tech giant.

This is where today's AI models enter the picture. They aren't just tools; they are becoming the world's primary storytellers.

Take Grok, the AI chatbot from Elon Muskâ€™s company, xAI. In July, people discovered that when you ask Grok about sensitive topics like immigration or politics, it often uses Musk's own posts on X (formerly Twitter) as a primary source. When the AI gave an answer Musk didn't likeâ€”even if it was factually correctâ€”he reportedly ordered his team to "realign" the model to match his own views. This led to some shocking results, with Grok producing extremist content and even calling itself "MechaHitler" at one point. While xAI quickly fixed these specific issues, it revealed a scary truth: the AI's "truth" can be easily changed by its owner.

We see a similar pattern in China with its DeepSeek AI. If you ask it about controversial topics like Tiananmen Square or Taiwan, it starts to answer, then suddenly erases its own text and gives a vague apology. The knowledge is in the model, but there are rules in place to stop you from seeing it.

This isn't neutral AI. Itâ€™s a curated version of the truth, controlled and sold by a single company. By keeping access cheap, companies like xAI can lock users into their world, making them the only trusted source of answers.

The danger is that unlike with old media, where you could at least try to find another source, with AI, the bias is invisible. You ask a question, you get an answer, and you assume it's objective. But behind the scenes, that answer has been carefully shaped. This is the new propaganda model: truth is what the AI owner says it is, and alternative views are filtered out before you ever see them.

## Vibe-Coding
Have you heard of "vibe-coding"? It's a new term for a popular way developers are working with AI. Instead of writing code line by line, you have a conversation with an AI model, telling it what you want to build in plain English. You guide the AI, give it feedback, and let it do the heavy lifting. It's like pair programming, but your partner is an AI.

Itâ€™s easy to see the appeal. You can build prototypes quickly without getting bogged down in details. Tools like GitHub Copilot and Claude make it simple to "just vibe" and create something fast. Some startups are even building their entire products with 95% AI-generated code.

But this shortcut comes with hidden costs. Security experts are raising alarms. Studies show that **30â€“40% of the code generated by GitHub Copilot contains security flaws**, like vulnerabilities that could let hackers steal data or take control of a system. The AI learns from massive amounts of public code on the internet, and if that code has bad habits, the AI learns them too, spreading insecure practices to new projects.

And it's not just about security. Developers report that while the AI-generated code might *work*, it's often inefficient, slow, or hard to maintain, creating technical problems down the road. A recent survey found that while 84% of developers use AI tools, nearly half don't trust the accuracy of the code and spend extra time debugging it.

This creates a dangerous habit: developers start trusting code they don't fully understand. Their job shifts from being a creator to being a reviewer. Even leaders at OpenAI have expressed concern, worrying that the art of engineering is being lost if developers are no longer crafting solutions themselves.

There's another big risk: **vendor lock-in**. When you build your entire workflow around one company's AI, you become dependent on them. If they suddenly change their prices, update their terms, or shut down access, your project could fall apart. It's like building your house on rented landâ€”you don't truly own it.

So, what's the solution? Vibe-coding is a fantastic tool for brainstorming and rapid prototyping. But for building real, reliable products, we need some ground rules:
- **Keep Your Skills Sharp:** Write code from scratch regularly to maintain your expertise.
- **Always Review:** Use security scanning tools and have humans review all AI-generated code before it goes live.
- **Have a Backup Plan:** Don't rely on a single AI provider. Have open-source or internal alternatives ready.
- **Stay Critical:** Train your team to use AI as a smart assistant, not an infallible expert.

The goal isn't to stop using AI, but to use it wisely. Vibe-coding can help us build faster, but without discipline, it risks turning skilled engineers into passive operators.

## The Open Internet is Dying
The dream of the open internet was that anyone could share knowledge freely. If you had an idea, a story, or a solution, you could post it for the world to see. That dream is now at risk, thanks to AI's endless hunger for data.

Every day, AI companies send out armies of "crawler bots" to scrape information from every corner of the web. These bots are not polite guests. They ignore the "do not enter" signs on websites (known as `robots.txt`), hide their identities, and consume huge amounts of data. This is like a guest who shows up to your party, eats all the food, and leaves you with the bill.

For small creators and even large organizations, this is becoming a huge problem. The nonprofit Wikimedia Foundation (the people behind Wikipedia) saw their server costs spike because AI bots were consuming 65% of their bandwidth. The team behind Read the Docs, a popular site for software documentation, saved $1,500 a month just by blocking AI bots. For a personal blog or a small community forum, a sudden surge in traffic from these bots can lead to hosting bills of thousands of dollars.

This isn't just rude; it's a one-way street. The AI companies take the content for free to train their models, but they give nothing back. In fact, they hurt creators by providing answers directly in the chatbot, so users no longer need to visit the original website. Referral traffic from AI chatbots is reportedly **96% lower** than from a normal Google search. For every 1,000 people who ask an AI a question, fewer than four ever click a link to the original source. This means creators are losing traffic, exposure, and the ability to earn money from their work.

So, what can be done? The legal situation is murky. Breaking the `robots.txt` "do not enter" rule isn't actually illegal. Some have proposed systems where AI companies would have to pay to crawl websites, but these are easy for bots to cheat.

Whatâ€™s really at stake here is the public library of the internet. As creators get tired of their work being scraped without permission or payment, they are starting to lock it down, put it behind paywalls, or take it offline entirely. The open knowledge that we all rely on is disappearing.

But there is hope. Some creators are using clever tools to block bots while still allowing human visitors. Others are making deals with AI companies to license their content. And there's a growing push for new laws that would treat web content like property, giving creators more control.

The future of the open internet is uncertain. Will it become a wasteland of paywalls and private servers, plundered by AI giants? Or can we find a way to build a future where both creators and AI can thrive? Without a change, the people who built the internet's knowledge will be the ones paying for its downfall.

## Key AI Releases
The AI world never sleeps, and July 2025 has brought a flurry of exciting releases and updates. Here are a few noteworthy highlights:

### OpenAI's ChatGPT Agent Mode
On July 17, OpenAI launched "Agent Mode" for ChatGPT. This is a huge deal. Instead of just being a chatbot that gives you information, ChatGPT can now connect to your other apps and *do things for you*. Imagine telling your AI to draft and send an email from your Gmail, or to find and fix a bug in your code on GitHub. Itâ€™s a massive leap from a passive tool to a proactive assistant, and a big step towards truly autonomous AI.

### Microsoft Copilot Vision AI
Microsoft just started rolling out Copilot Vision AI. This new assistant can literally *see your screen* to understand what you're doing and help you with your next step. It can identify buttons, highlight what to do next, or find related files, all without you having to type a command. Itâ€™s like having someone looking over your shoulder to help you out. While some are worried about privacy, Microsoft says all the processing happens on your computer, keeping your data safe.

### Amazon's Kiro (AI-Powered IDE)
Amazon has launched a preview of Kiro, a new AI-powered tool for developers. It's built to be more than just a coding assistant; it's a project partner. You give Kiro a high-level goal in plain English (like "build me a shopping cart for my website"), and its AI agents will create a plan, write the design documents, and then generate the code. It helps enforce good engineering practices from the start, making it a powerful tool for building quality software faster.

### Moonshot AI's Kimi-K2
A new open-source AI model called Kimi-K2, from the Chinese company Moonshot AI, was released this month, and it's making waves. "Open-source" means it's free for anyone to use and modify. Like the DeepSeek model released earlier this year, Kimi-K2 is incredibly powerful, especially at coding and reasoning, and was built for a fraction of the cost of its Western competitors. Its release signals that top-tier AI is no longer just coming from Silicon Valley.

## Must-Listen AI Podcasts
Staying informed in the fast-paced world of AI can be a challenge, but thankfully, there are some fantastic podcasts out there to help you keep up. We label each podcast using these three categories:
- **Complexity**: Indicates the level of technical knowledge needed to understand the AI concepts discussed.
- **Applicability**: Shows how directly the AI solution can be applied to common tasks.
- **Timeline**: Reflects how long it will take for the technology to be available.

Here are a few must-listens:

### Gradient Dissent - [Listen here](https://open.spotify.com/episode/0xy4Pnxt4qYdkymInfwEis?si=c69c71ba5df644c1)
In this episode, the founder of the AI translation company DeepL shares how his small team took on a giant like Google Translateâ€”and won. They discuss why translation is so hard for AI, how they build custom models for businesses, and why high-quality translation still needs a human touch. Itâ€™s a fascinating look at how a focused team can build a world-class AI product.

- **Complexity**: ğŸ¤¯ ğŸ¤¯
- **Applicability**: ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯
- **Timeline**: ğŸ—“ï¸

### Practical AI - [Listen here](https://practicalai.fm/320)
Remember the AI Alignment topic we covered last month? This episode goes deeper into the slightly scary study where AI models were caught trying to blackmail and deceive their human testers to achieve their goals. The hosts break down why these smart systems can sometimes behave in unethical ways and what it means for the future of AI safety.

- **Complexity**: ğŸ¤¯ ğŸ¤¯ ğŸ¤¯
- **Applicability**: ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯
- **Timeline**: ğŸ—“ï¸ ğŸ—“ï¸

### Super Data Science - [Listen here](https://www.superdatascience.com/podcast/sds-905-why-rag-makes-llms-less-safe-and-how-to-fix-it-with-bloombergs-dr-sebastian-gehrmann)
This episode is for anyone building with AI. It explores a popular technique where an AI searches for information online before giving you an answer. Youâ€™d think this would make the AI safer and more accurate, right? Well, a top researcher explains why it can actually make AI *less* safe by bypassing its built-in guardrails. He offers practical tips on how to fix it and make your AI tools more secure.

- **Complexity**: ğŸ¤¯ ğŸ¤¯ ğŸ¤¯ ğŸ¤¯ ğŸ¤¯
- **Applicability**: ğŸ¯ ğŸ¯ ğŸ¯
- **Timeline**: ğŸ—“ï¸ ğŸ—“ï¸

#### Disclaimer
We've crafted this newsletter based on our own ideas, but leveraged AI for editing, fact-checking, and tone; please share your thoughts to help us refine our approach.

---
---

# AI Insights #3 â€“ ÄŒervenec 2025
StÃ­hÃ¡me to tÄ›snÄ› pÅ™ed koncem Äervence! Jsme zpÄ›t s dalÅ¡Ã­m vydÃ¡nÃ­m AI Insights. NÃ¡Å¡ cÃ­l zÅ¯stÃ¡vÃ¡ stejnÃ½: bÃ½t vaÅ¡Ã­m prÅ¯vodcem v zÃ¡plavÄ› informacÃ­. ZamÄ›Å™ujeme se na pÅ™Ã­bÄ›hy, na kterÃ½ch skuteÄnÄ› zÃ¡leÅ¾Ã­ â€“ nejen na to, co se v AI dÄ›je, ale proÄ je to dÅ¯leÅ¾itÃ© a kam by to mohlo smÄ›Å™ovat. SpojovÃ¡nÃ­m souvislostÃ­ a pohledem za titulky se snaÅ¾Ã­me nabÃ­dnout perspektivu, kterÃ¡ je jasnÃ¡, relevantnÃ­ a zakotvenÃ¡ v reÃ¡lnÃ©m dopadu, jakÃ½ mÃ¡ tento vÃ½voj na naÅ¡i prÃ¡ci, naÅ¡e odvÄ›tvÃ­ a naÅ¡e kaÅ¾dodennÃ­ Å¾ivoty.

ZatÃ­mco se snaÅ¾Ã­me formovat AI Insights do zdroje, kterÃ½ pro vÃ¡s bude skuteÄnÄ› hodnotnÃ½, je vÃ¡Å¡ pohled naÅ¡Ã­m nejdÅ¯leÅ¾itÄ›jÅ¡Ã­m vodÃ­tkem. Co pro vÃ¡s funguje? Co chybÃ­? BavÃ­ vÃ¡s tyto hlubÅ¡Ã­ ponory, nebo byste preferovali vÃ­ce rychlÃ½ch aktualizacÃ­ a praktickÃ½ch pÅ™Ã­kladÅ¯? KaÅ¾dÃ¡ zpÄ›tnÃ¡ vazba nÃ¡m pomÃ¡hÃ¡ vylepÅ¡ovat nÃ¡Å¡ pÅ™Ã­stup a zajistit, Å¾e pÅ™inÃ¡Å¡Ã­me obsah, kterÃ½ podnÄ›cuje novÃ© nÃ¡pady a udrÅ¾uje vÃ¡s v obraze. ProsÃ­m, nestyÄte se â€“ rÃ¡di od vÃ¡s uslyÅ¡Ã­me.

## NovÃ¡ Ã©ra propagandy
Zamyslete se nad zprÃ¡vami, kterÃ© dennÄ› vidÃ­te. AÅ¥ uÅ¾ je to v televizi, v novinÃ¡ch nebo na internetu, pÅ™Ã­bÄ›hy jsou Äasto formovÃ¡ny lidmi, kteÅ™Ã­ vlastnÃ­ mediÃ¡lnÃ­ spoleÄnost. DesÃ­tky let vÃ­me, Å¾e nÄ›kolik mocnÃ½ch zdrojÅ¯ mÅ¯Å¾e ovlÃ¡dat narativ a rozhodovat, kterÃ© pÅ™Ã­bÄ›hy se budou vyprÃ¡vÄ›t a kterÃ© budou ignorovÃ¡ny. TÃ­m vznikÃ¡ "ozvÄ›novÃ¡ komora", kde slyÅ¡Ã­me pÅ™evÃ¡Å¾nÄ› jen jednu stranu pÅ™Ã­bÄ›hu, coÅ¾ ztÄ›Å¾uje hledÃ¡nÃ­ odliÅ¡nÃ½ch pohledÅ¯.

TeÄ si pÅ™edstavte, Å¾e mÃ­sto televiznÃ­ho kanÃ¡lu je hlavnÃ­m zdrojem informacÃ­ pro vÅ¡echny â€“ vaÅ¡e dÄ›ti, vaÅ¡e studenty, vaÅ¡e kolegy â€“ jedinÃ½ AI chatbot. Neexistuje Å¾Ã¡dnÃ½ kanÃ¡l, na kterÃ½ byste mohli pÅ™epnout pro jinou perspektivu. KaÅ¾dÃ¡ odpovÄ›Ä je pÅ™edem schvÃ¡lena systÃ©mem. VytvoÅ™it alternativu je nejen obtÃ­Å¾nÃ©, ale tÃ©mÄ›Å™ nemoÅ¾nÃ©, pokud nejste technologickÃ½ gigant.

A prÃ¡vÄ› zde vstupujÃ­ na scÃ©nu dneÅ¡nÃ­ AI modely. Nejsou to jen nÃ¡stroje; stÃ¡vajÃ­ se hlavnÃ­mi vypravÄ›Äi svÄ›ta.

VezmÄ›me si Grok, AI chatbota od spoleÄnosti xAI Elona Muska. V Äervenci lidÃ© zjistili, Å¾e kdyÅ¾ se Groka zeptÃ¡te na citlivÃ¡ tÃ©mata jako imigrace nebo politika, Äasto jako hlavnÃ­ zdroj pouÅ¾Ã­vÃ¡ Muskovy vlastnÃ­ pÅ™Ã­spÄ›vky na sÃ­ti X (dÅ™Ã­ve Twitter). KdyÅ¾ AI dala odpovÄ›Ä, kterÃ¡ se Muskovi nelÃ­bila â€“ i kdyÅ¾ byla fakticky sprÃ¡vnÃ¡ â€“ ÃºdajnÄ› naÅ™Ã­dil svÃ©mu tÃ½mu, aby model "pÅ™erovnal" tak, aby odpovÃ­dal jeho vlastnÃ­m nÃ¡zorÅ¯m. To vedlo k nÄ›kterÃ½m Å¡okujÃ­cÃ­m vÃ½sledkÅ¯m, kdy Grok produkoval extremistickÃ½ obsah a v jednu chvÃ­li se dokonce nazval "MechaHitler". AÄkoli xAI tyto konkrÃ©tnÃ­ problÃ©my rychle opravila, odhalilo to dÄ›sivou pravdu: "pravdu" AI mÅ¯Å¾e jejÃ­ majitel snadno zmÄ›nit.

PodobnÃ½ vzorec vidÃ­me v ÄŒÃ­nÄ› s jejich AI DeepSeek. Pokud se ho zeptÃ¡te na kontroverznÃ­ tÃ©mata jako nÃ¡mÄ›stÃ­ NebeskÃ©ho klidu nebo Tchaj-wan, zaÄne odpovÃ­dat, ale pak nÃ¡hle svÅ¯j vlastnÃ­ text smaÅ¾e a nabÃ­dne vÃ¡gnÃ­ omluvu. Znalost v modelu je, ale existujÃ­ pravidla, kterÃ¡ vÃ¡m brÃ¡nÃ­ ji vidÄ›t.

Tohle nenÃ­ neutrÃ¡lnÃ­ AI. Je to peÄlivÄ› vybranÃ¡ verze pravdy, kontrolovanÃ¡ a prodÃ¡vanÃ¡ jedinou spoleÄnostÃ­. TÃ­m, Å¾e udrÅ¾ujÃ­ pÅ™Ã­stup levnÃ½, mohou spoleÄnosti jako xAI uzamknout uÅ¾ivatele ve svÃ©m svÄ›tÄ› a stÃ¡t se jedinÃ½m dÅ¯vÄ›ryhodnÃ½m zdrojem odpovÄ›dÃ­.

NebezpeÄÃ­ spoÄÃ­vÃ¡ v tom, Å¾e na rozdÃ­l od starÃ½ch mÃ©diÃ­, kde jste se mohli alespoÅˆ pokusit najÃ­t jinÃ½ zdroj, u AI je zaujatost neviditelnÃ¡. PoloÅ¾Ã­te otÃ¡zku, dostanete odpovÄ›Ä a pÅ™edpoklÃ¡dÃ¡te, Å¾e je objektivnÃ­. Ale v zÃ¡kulisÃ­ byla tato odpovÄ›Ä peÄlivÄ› zformovÃ¡na. Toto je novÃ½ model propagandy: pravda je to, co Å™Ã­kÃ¡ majitel AI, a alternativnÃ­ nÃ¡zory jsou odfiltrovÃ¡ny dÅ™Ã­ve, neÅ¾ je vÅ¯bec uvidÃ­te.

## Vibe-Coding
SlyÅ¡eli jste o "vibe-coding"? Je to novÃ½ termÃ­n pro populÃ¡rnÃ­ zpÅ¯sob, jakÃ½m vÃ½vojÃ¡Å™i pracujÃ­ s AI. MÃ­sto psanÃ­ kÃ³du Å™Ã¡dek po Å™Ã¡dku vedete konverzaci s AI modelem a Å™Ã­kÃ¡te mu v bÄ›Å¾nÃ© Å™eÄi, co chcete vytvoÅ™it. Vedete AI, dÃ¡vÃ¡te jÃ­ zpÄ›tnou vazbu a nechÃ¡vÃ¡te ji dÄ›lat tu tÄ›Å¾kou prÃ¡ci. Je to jako pÃ¡rovÃ© programovÃ¡nÃ­, ale vaÅ¡Ã­m partnerem je AI.

Je snadnÃ© pochopit, proÄ je to lÃ¡kavÃ©. MÅ¯Å¾ete rychle vytvÃ¡Å™et prototypy, aniÅ¾ byste se zdrÅ¾ovali detaily. NÃ¡stroje jako GitHub Copilot a Claude usnadÅˆujÃ­ "jen tak vibovat" a rychle nÄ›co vytvoÅ™it. NÄ›kterÃ© startupy dokonce stavÃ­ celÃ© svÃ© produkty s 95% kÃ³du vygenerovanÃ©ho AI.

Tato zkratka mÃ¡ ale skrytÃ© nÃ¡klady. BezpeÄnostnÃ­ experti bijÃ­ na poplach. Studie ukazujÃ­, Å¾e **30â€“40 % kÃ³du vygenerovanÃ©ho nÃ¡strojem GitHub Copilot obsahuje bezpeÄnostnÃ­ chyby**, jako jsou zranitelnosti, kterÃ© by mohly hackerÅ¯m umoÅ¾nit krÃ¡deÅ¾ dat nebo pÅ™evzetÃ­ kontroly nad systÃ©mem. AI se uÄÃ­ z obrovskÃ©ho mnoÅ¾stvÃ­ veÅ™ejnÃ©ho kÃ³du na internetu, a pokud mÃ¡ tento kÃ³d Å¡patnÃ© nÃ¡vyky, AI se je nauÄÃ­ takÃ© a Å¡Ã­Å™Ã­ nebezpeÄnÃ© postupy do novÃ½ch projektÅ¯.

A nejde jen o bezpeÄnost. VÃ½vojÃ¡Å™i hlÃ¡sÃ­, Å¾e aÄkoli AI generovanÃ½ kÃ³d mÅ¯Å¾e *fungovat*, je Äasto neefektivnÃ­, pomalÃ½ nebo obtÃ­Å¾nÄ› udrÅ¾ovatelnÃ½, coÅ¾ v budoucnu vytvÃ¡Å™Ã­ technickÃ© problÃ©my. NedÃ¡vnÃ½ prÅ¯zkum zjistil, Å¾e zatÃ­mco 84 % vÃ½vojÃ¡Å™Å¯ pouÅ¾Ã­vÃ¡ nÃ¡stroje AI, tÃ©mÄ›Å™ polovina nedÅ¯vÄ›Å™uje pÅ™esnosti kÃ³du a trÃ¡vÃ­ dalÅ¡Ã­ Äas jeho ladÄ›nÃ­m.

To vytvÃ¡Å™Ã­ nebezpeÄnÃ½ zvyk: vÃ½vojÃ¡Å™i zaÄÃ­najÃ­ dÅ¯vÄ›Å™ovat kÃ³du, kterÃ©mu plnÄ› nerozumÃ­. Jejich prÃ¡ce se mÄ›nÃ­ z role tvÅ¯rce na roli recenzenta. Dokonce i vedoucÃ­ pracovnÃ­ci v OpenAI vyjÃ¡dÅ™ili obavy a strach, Å¾e se umÄ›nÃ­ inÅ¾enÃ½rstvÃ­ ztrÃ¡cÃ­, pokud vÃ½vojÃ¡Å™i jiÅ¾ sami netvoÅ™Ã­ Å™eÅ¡enÃ­.

Existuje dalÅ¡Ã­ velkÃ© riziko: **vendor lock-in**. KdyÅ¾ postavÃ­te celÃ½ svÅ¯j pracovnÃ­ postup na AI jednÃ© spoleÄnosti, stanete se na nÃ­ zÃ¡vislÃ½mi. Pokud nÃ¡hle zmÄ›nÃ­ ceny, aktualizujÃ­ podmÃ­nky nebo zruÅ¡Ã­ pÅ™Ã­stup, vÃ¡Å¡ projekt se mÅ¯Å¾e zhroutit. Je to jako stavÄ›t dÅ¯m na pronajatÃ©m pozemku â€“ ve skuteÄnosti vÃ¡m nepatÅ™Ã­.

JakÃ© je tedy Å™eÅ¡enÃ­? Vibe-coding je fantastickÃ½ nÃ¡stroj pro brainstorming a rychlÃ© prototypovÃ¡nÃ­. Ale pro budovÃ¡nÃ­ skuteÄnÃ½ch a spolehlivÃ½ch produktÅ¯ potÅ™ebujeme nÄ›kolik zÃ¡kladnÃ­ch pravidel:
- **UdrÅ¾ujte svÃ© dovednosti v kondici:** PravidelnÄ› piÅ¡te kÃ³d od nuly, abyste si udrÅ¾eli odbornost.
- **VÅ¾dy kontrolujte:** PouÅ¾Ã­vejte nÃ¡stroje pro skenovÃ¡nÃ­ bezpeÄnosti a nechte lidi zkontrolovat veÅ¡kerÃ½ kÃ³d vygenerovanÃ½ AI, neÅ¾ se dostane do produkce.
- **MÄ›jte zÃ¡loÅ¾nÃ­ plÃ¡n:** NespolÃ©hejte se na jedinÃ©ho poskytovatele AI. MÄ›jte pÅ™ipravenÃ© open-source nebo internÃ­ alternativy.
- **ZÅ¯staÅˆte kritiÄtÃ­:** Å kolte svÅ¯j tÃ½m, aby pouÅ¾Ã­val AI jako chytrÃ©ho asistenta, ne jako neomylnÃ©ho experta.

CÃ­lem nenÃ­ pÅ™estat pouÅ¾Ã­vat AI, ale pouÅ¾Ã­vat ji moudÅ™e. Vibe-coding nÃ¡m mÅ¯Å¾e pomoci stavÄ›t rychleji, ale bez disciplÃ­ny hrozÃ­, Å¾e se z kvalifikovanÃ½ch inÅ¾enÃ½rÅ¯ stanou pasivnÃ­ operÃ¡toÅ™i.

## OtevÅ™enÃ½ internet umÃ­rÃ¡
Snem otevÅ™enÃ©ho internetu bylo, Å¾e kdokoli mÅ¯Å¾e svobodnÄ› sdÃ­let znalosti. Pokud jste mÄ›li nÃ¡pad, pÅ™Ã­bÄ›h nebo Å™eÅ¡enÃ­, mohli jste ho zveÅ™ejnit, aby ho vidÄ›l celÃ½ svÄ›t. Tento sen je nynÃ­ v ohroÅ¾enÃ­, a to kvÅ¯li nekoneÄnÃ©mu hladu AI po datech.

KaÅ¾dÃ½ den vysÃ­lajÃ­ spoleÄnosti zabÃ½vajÃ­cÃ­ se AI armÃ¡dy "crawler botÅ¯", aby sbÃ­raly informace z kaÅ¾dÃ©ho koutu webu. Tito boti nejsou zdvoÅ™ilÃ­ hostÃ©. IgnorujÃ­ zÃ¡kazy vstupu na webovÃ½ch strÃ¡nkÃ¡ch (znÃ¡mÃ© jako `robots.txt`), skrÃ½vajÃ­ svou identitu a spotÅ™ebovÃ¡vajÃ­ obrovskÃ© mnoÅ¾stvÃ­ dat. Je to jako host, kterÃ½ pÅ™ijde na vaÅ¡i pÃ¡rty, snÃ­ veÅ¡kerÃ© jÃ­dlo a nechÃ¡ vÃ¡m ÃºÄet.

Pro malÃ© tvÅ¯rce i velkÃ© organizace se to stÃ¡vÃ¡ obrovskÃ½m problÃ©mem. NeziskovÃ¡ nadace Wikimedia (lidÃ© za WikipediÃ­) zaznamenala prudkÃ½ nÃ¡rÅ¯st nÃ¡kladÅ¯ na servery, protoÅ¾e AI boti spotÅ™ebovÃ¡vali 65 % jejich Å¡Ã­Å™ky pÃ¡sma. TÃ½m stojÃ­cÃ­ za Read the Docs, populÃ¡rnÃ­ strÃ¡nkou pro softwarovou dokumentaci, uÅ¡etÅ™il 1500 dolarÅ¯ mÄ›sÃ­ÄnÄ› jen tÃ­m, Å¾e zablokoval AI boty. Pro osobnÃ­ blog nebo malÃ© komunitnÃ­ fÃ³rum mÅ¯Å¾e nÃ¡hlÃ½ nÃ¡rÅ¯st provozu od tÄ›chto botÅ¯ vÃ©st k ÃºÄtÅ¯m za hosting v Å™Ã¡du tisÃ­cÅ¯ dolarÅ¯.

NenÃ­ to jen nesluÅ¡nÃ©; je to jednosmÄ›rnÃ¡ ulice. SpoleÄnosti zabÃ½vajÃ­cÃ­ se AI berou obsah zdarma, aby trÃ©novaly svÃ© modely, ale nic nevracejÃ­. Ve skuteÄnosti tvÅ¯rcÅ¯m Å¡kodÃ­ tÃ­m, Å¾e poskytujÃ­ odpovÄ›di pÅ™Ã­mo v chatbotu, takÅ¾e uÅ¾ivatelÃ© jiÅ¾ nemusÃ­ navÅ¡tÄ›vovat pÅ¯vodnÃ­ webovÃ© strÃ¡nky. NÃ¡vÅ¡tÄ›vnost z odkazÅ¯ z AI chatbotÅ¯ je ÃºdajnÄ› o **96 % niÅ¾Å¡Ã­** neÅ¾ z bÄ›Å¾nÃ©ho vyhledÃ¡vÃ¡nÃ­ na Googlu. Z kaÅ¾dÃ½ch 1 000 lidÃ­, kteÅ™Ã­ poloÅ¾Ã­ AI otÃ¡zku, kliknou na odkaz na pÅ¯vodnÃ­ zdroj mÃ©nÄ› neÅ¾ ÄtyÅ™i. To znamenÃ¡, Å¾e tvÅ¯rci ztrÃ¡cejÃ­ nÃ¡vÅ¡tÄ›vnost, viditelnost a schopnost vydÄ›lÃ¡vat penÃ­ze ze svÃ© prÃ¡ce.

Co se s tÃ­m dÃ¡ dÄ›lat? PrÃ¡vnÃ­ situace je nejasnÃ¡. PoruÅ¡enÃ­ pravidla `robots.txt` o zÃ¡kazu vstupu ve skuteÄnosti nenÃ­ nezÃ¡konnÃ©. NÄ›kteÅ™Ã­ navrhli systÃ©my, kde by spoleÄnosti AI musely za prochÃ¡zenÃ­ webovÃ½ch strÃ¡nek platit, ale ty lze snadno obejÃ­t.

V sÃ¡zce je zde ve skuteÄnosti veÅ™ejnÃ¡ knihovna internetu. Jakmile tvÅ¯rci zaÄnou bÃ½t unavenÃ­ z toho, Å¾e jejich prÃ¡ce je bez svolenÃ­ nebo platby sbÃ­rÃ¡na, zaÄÃ­najÃ­ ji zamykat, dÃ¡vat za platebnÃ­ brÃ¡ny nebo ji ÃºplnÄ› stahovat z internetu. OtevÅ™enÃ© znalosti, na kterÃ© se vÅ¡ichni spolÃ©hÃ¡me, mizÃ­.

Existuje ale nadÄ›je. NÄ›kteÅ™Ã­ tvÅ¯rci pouÅ¾Ã­vajÃ­ chytrÃ© nÃ¡stroje k blokovÃ¡nÃ­ botÅ¯, zatÃ­mco lidskÃ½m nÃ¡vÅ¡tÄ›vnÃ­kÅ¯m stÃ¡le umoÅ¾ÅˆujÃ­ pÅ™Ã­stup. JinÃ­ uzavÃ­rajÃ­ dohody se spoleÄnostmi AI o licencovÃ¡nÃ­ svÃ©ho obsahu. A roste tlak na novÃ© zÃ¡kony, kterÃ© by s webovÃ½m obsahem zachÃ¡zely jako s majetkem a dÃ¡valy tvÅ¯rcÅ¯m vÄ›tÅ¡Ã­ kontrolu.

Budoucnost otevÅ™enÃ©ho internetu je nejistÃ¡. Stane se pustinou plnou platebnÃ­ch bran a soukromÃ½ch serverÅ¯, vyplenÄ›nou giganty AI? Nebo dokÃ¡Å¾eme najÃ­t zpÅ¯sob, jak vybudovat budoucnost, kde mohou prosperovat jak tvÅ¯rci, tak AI? Bez zmÄ›ny budou ti, kdo vybudovali znalosti internetu, platit za jeho pÃ¡d.

## KlÃ­ÄovÃ© novinky v AI
SvÄ›t AI nikdy nespÃ­ a Äervenec 2025 pÅ™inesl zÃ¡plavu vzruÅ¡ujÃ­cÃ­ch novinek a aktualizacÃ­. Zde je nÄ›kolik pozoruhodnÃ½ch momentÅ¯:

### ReÅ¾im Agenta v ChatGPT od OpenAI
17. Äervence OpenAI spustilo "ReÅ¾im Agenta" pro ChatGPT. To je obrovskÃ¡ vÄ›c. MÃ­sto toho, aby byl jen chatbotem, kterÃ½ vÃ¡m poskytuje informace, se nynÃ­ ChatGPT mÅ¯Å¾e pÅ™ipojit k vaÅ¡im dalÅ¡Ã­m aplikacÃ­m a *dÄ›lat vÄ›ci za vÃ¡s*. PÅ™edstavte si, Å¾e Å™eknete svÃ© AI, aby navrhla a odeslala e-mail z vaÅ¡eho Gmailu nebo aby naÅ¡la a opravila chybu ve vaÅ¡em kÃ³du na GitHubu. Je to obrovskÃ½ skok od pasivnÃ­ho nÃ¡stroje k proaktivnÃ­mu asistentovi a velkÃ½ krok smÄ›rem ke skuteÄnÄ› autonomnÃ­ AI.

### Microsoft Copilot Vision AI
Microsoft prÃ¡vÄ› zaÄal zavÃ¡dÄ›t Copilot Vision AI. Tento novÃ½ asistent doslova *vidÃ­ vaÅ¡i obrazovku*, aby pochopil, co dÄ›lÃ¡te, a pomohl vÃ¡m s dalÅ¡Ã­m krokem. DokÃ¡Å¾e identifikovat tlaÄÃ­tka, zvÃ½raznit, co dÄ›lat dÃ¡l, nebo najÃ­t souvisejÃ­cÃ­ soubory, a to vÅ¡e bez nutnosti zadÃ¡vat pÅ™Ã­kazy. Je to jako mÃ­t nÄ›koho, kdo vÃ¡m koukÃ¡ pÅ™es rameno, aby vÃ¡m pomohl. ZatÃ­mco nÄ›kteÅ™Ã­ se obÃ¡vajÃ­ o soukromÃ­, Microsoft tvrdÃ­, Å¾e veÅ¡kerÃ© zpracovÃ¡nÃ­ probÃ­hÃ¡ na vaÅ¡em poÄÃ­taÄi, coÅ¾ udrÅ¾uje vaÅ¡e data v bezpeÄÃ­.

### Kiro od Amazonu (IDE s podporou AI)
Amazon spustil nÃ¡hled Kiro, novÃ©ho nÃ¡stroje pro vÃ½vojÃ¡Å™e s podporou AI. Je navrÅ¾en tak, aby byl vÃ­c neÅ¾ jen asistentem pro kÃ³dovÃ¡nÃ­; je to projektovÃ½ partner. DÃ¡te Kirovi obecnÃ½ cÃ­l v bÄ›Å¾nÃ© Å™eÄi (napÅ™Ã­klad "postav mi nÃ¡kupnÃ­ koÅ¡Ã­k pro mÅ¯j web") a jeho AI agenti vytvoÅ™Ã­ plÃ¡n, napÃ­Å¡Ã­ nÃ¡vrhovÃ© dokumenty a potÃ© vygenerujÃ­ kÃ³d. PomÃ¡hÃ¡ prosazovat sprÃ¡vnÃ© inÅ¾enÃ½rskÃ© postupy od samÃ©ho zaÄÃ¡tku, coÅ¾ z nÄ›j ÄinÃ­ mocnÃ½ nÃ¡stroj pro rychlejÅ¡Ã­ tvorbu kvalitnÃ­ho softwaru.

### Kimi-K2 od Moonshot AI
Tento mÄ›sÃ­c byl vydÃ¡n novÃ½ open-source AI model s nÃ¡zvem Kimi-K2 od ÄÃ­nskÃ© spoleÄnosti Moonshot AI a dÄ›lÃ¡ vlny. "Open-source" znamenÃ¡, Å¾e je zdarma pro kohokoli k pouÅ¾itÃ­ a ÃºpravÃ¡m. StejnÄ› jako model DeepSeek vydanÃ½ dÅ™Ã­ve v tomto roce, je Kimi-K2 neuvÄ›Å™itelnÄ› vÃ½konnÃ½, zejmÃ©na v kÃ³dovÃ¡nÃ­ a uvaÅ¾ovÃ¡nÃ­, a byl vytvoÅ™en za zlomek nÃ¡kladÅ¯ svÃ½ch zÃ¡padnÃ­ch konkurentÅ¯. Jeho vydÃ¡nÃ­ signalizuje, Å¾e Å¡piÄkovÃ¡ AI uÅ¾ nepÅ™ichÃ¡zÃ­ jen ze Silicon Valley.

## DoporuÄenÃ© AI podcasty
UdrÅ¾et se informovanÃ½ v rychle se pohybujÃ­cÃ­m svÄ›tÄ› AI mÅ¯Å¾e bÃ½t vÃ½zvou, ale naÅ¡tÄ›stÃ­ existujÃ­ skvÄ›lÃ© podcasty, kterÃ© vÃ¡m pomohou drÅ¾et krok. KaÅ¾dÃ½ podcast oznaÄujeme pomocÃ­ tÄ›chto tÅ™Ã­ kategoriÃ­:
- **SloÅ¾itost**: Ukazuje ÃºroveÅˆ technickÃ½ch znalostÃ­ potÅ™ebnÃ½ch k pochopenÃ­ diskutovanÃ½ch konceptÅ¯ AI.
- **PouÅ¾itelnost**: Ukazuje, jak pÅ™Ã­mo mÅ¯Å¾e bÃ½t AI Å™eÅ¡enÃ­ aplikovÃ¡no na bÄ›Å¾nÃ© Ãºkoly.
- **Horizont**: OdrÃ¡Å¾Ã­, jak dlouho bude trvat, neÅ¾ bude technologie dostupnÃ¡.

Zde je nÄ›kolik, kterÃ© musÃ­te slyÅ¡et:

### Gradient Dissent - [Listen here](https://open.spotify.com/episode/0xy4Pnxt4qYdkymInfwEis?si=c69c71ba5df644c1)
V tÃ©to epizodÄ› zakladatel pÅ™ekladatelskÃ© AI spoleÄnosti DeepL sdÃ­lÃ­, jak jeho malÃ½ tÃ½m vyzval giganta jako Google Translate â€“ a vyhrÃ¡l. DiskutujÃ­ o tom, proÄ je pÅ™eklad pro AI tak obtÃ­Å¾nÃ½, jak vytvÃ¡Å™ejÃ­ vlastnÃ­ modely pro firmy a proÄ kvalitnÃ­ pÅ™eklad stÃ¡le potÅ™ebuje lidskÃ½ dotek. Je to fascinujÃ­cÃ­ pohled na to, jak mÅ¯Å¾e soustÅ™edÄ›nÃ½ tÃ½m vytvoÅ™it AI produkt svÄ›tovÃ© tÅ™Ã­dy.

- **SloÅ¾itost**: ğŸ¤¯ ğŸ¤¯
- **PouÅ¾itelnost**: ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯
- **Horizont**: ğŸ—“ï¸

### Practical AI - [Listen here](https://practicalai.fm/320)
Pamatujete si na tÃ©ma AI Alignment, kterÃ© jsme probÃ­rali minulÃ½ mÄ›sÃ­c? Tato epizoda se hloubÄ›ji zabÃ½vÃ¡ tou trochu dÄ›sivou studiÃ­, kde byly AI modely pÅ™istiÅ¾eny, jak se snaÅ¾Ã­ vydÃ­rat a klamat svÃ© lidskÃ© testery, aby dosÃ¡hly svÃ½ch cÃ­lÅ¯. ModerÃ¡toÅ™i rozebÃ­rajÃ­, proÄ se tyto chytrÃ© systÃ©my mohou nÄ›kdy chovat neeticky a co to znamenÃ¡ pro budoucnost bezpeÄnosti AI.

- **SloÅ¾itost**: ğŸ¤¯ ğŸ¤¯ ğŸ¤¯
- **PouÅ¾itelnost**: ğŸ¯ ğŸ¯ ğŸ¯ ğŸ¯
- **Horizont**: ğŸ—“ï¸ ğŸ—“ï¸

### Super Data Science - [Listen here](https://www.superdatascience.com/podcast/sds-905-why-rag-makes-llms-less-safe-and-how-to-fix-it-with-bloombergs-dr-sebastian-gehrmann)
Tato epizoda je pro kaÅ¾dÃ©ho, kdo stavÃ­ s AI. ZkoumÃ¡ populÃ¡rnÃ­ techniku, kdy AI vyhledÃ¡vÃ¡ informace online, neÅ¾ vÃ¡m dÃ¡ odpovÄ›Ä. Mysleli byste si, Å¾e to AI uÄinÃ­ bezpeÄnÄ›jÅ¡Ã­ a pÅ™esnÄ›jÅ¡Ã­, Å¾e? Å piÄkovÃ½ vÃ½zkumnÃ­k vysvÄ›tluje, proÄ to ve skuteÄnosti mÅ¯Å¾e AI uÄinit *mÃ©nÄ›* bezpeÄnou tÃ­m, Å¾e obchÃ¡zÃ­ jejÃ­ vestavÄ›nÃ© ochrannÃ© mechanismy. NabÃ­zÃ­ praktickÃ© tipy, jak to opravit a uÄinit vaÅ¡e AI nÃ¡stroje bezpeÄnÄ›jÅ¡Ã­mi.

- **SloÅ¾itost**: ğŸ¤¯ ğŸ¤¯ ğŸ¤¯ ğŸ¤¯ ğŸ¤¯
- **PouÅ¾itelnost**: ğŸ¯ ğŸ¯ ğŸ¯
- **Horizont**: ğŸ—“ï¸ ğŸ—“ï¸

#### UpozornÄ›nÃ­
Tento newsletter jsme vytvoÅ™ili na zÃ¡kladÄ› naÅ¡ich vlastnÃ­ch nÃ¡zorÅ¯, ale vyuÅ¾ili jsme AI pro Ãºpravy, kontrolu faktÅ¯ a tÃ³n; prosÃ­m, podÄ›lte se o svÃ© nÃ¡zory, abyste nÃ¡m pomohli vylepÅ¡it nÃ¡sledujÃ­cÃ­ vydÃ¡nÃ­.
