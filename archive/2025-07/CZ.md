# AI Insights #3 – Červenec 2025
Stíháme to těsně před koncem července! Jsme zpět s dalším vydáním AI Insights. Náš cíl zůstává stejný: být vaším průvodcem v záplavě informací. Zaměřujeme se na příběhy, na kterých skutečně záleží – nejen na to, co se v AI děje, ale proč je to důležité a kam by to mohlo směřovat. Spojováním souvislostí a pohledem za titulky se snažíme nabídnout perspektivu, která je jasná, relevantní a zakotvená v reálném dopadu, jaký má tento vývoj na naši práci, naše odvětví a naše každodenní životy.

Zatímco se snažíme formovat AI Insights do zdroje, který pro vás bude skutečně hodnotný, je váš pohled naším nejdůležitějším vodítkem. Co pro vás funguje? Co chybí? Baví vás tyto hlubší ponory, nebo byste preferovali více rychlých aktualizací a praktických příkladů? Každá zpětná vazba nám pomáhá vylepšovat náš přístup a zajistit, že přinášíme obsah, který podněcuje nové nápady a udržuje vás v obraze. Prosím, nestyďte se – rádi od vás uslyšíme.

## Nová éra propagandy
Zamyslete se nad zprávami, které denně vidíte. Ať už je to v televizi, v novinách nebo na internetu, příběhy jsou často formovány lidmi, kteří vlastní mediální společnost. Desítky let víme, že několik mocných zdrojů může ovládat narativ a rozhodovat, které příběhy se budou vyprávět a které budou ignorovány. Tím vzniká "ozvěnová komora", kde slyšíme převážně jen jednu stranu příběhu, což ztěžuje hledání odlišných pohledů.

Teď si představte, že místo televizního kanálu je hlavním zdrojem informací pro všechny – vaše děti, vaše studenty, vaše kolegy – jediný AI chatbot. Neexistuje žádný kanál, na který byste mohli přepnout pro jinou perspektivu. Každá odpověď je předem schválena systémem. Vytvořit alternativu je nejen obtížné, ale téměř nemožné, pokud nejste technologický gigant.

A právě zde vstupují na scénu dnešní AI modely. Nejsou to jen nástroje; stávají se hlavními vypravěči světa.

Vezměme si Grok, AI chatbota od společnosti xAI Elona Muska. V červenci lidé zjistili, že když se Groka zeptáte na citlivá témata jako imigrace nebo politika, často jako hlavní zdroj používá Muskovy vlastní příspěvky na síti X (dříve Twitter). Když AI dala odpověď, která se Muskovi nelíbila – i když byla fakticky správná – údajně nařídil svému týmu, aby model "přerovnal" tak, aby odpovídal jeho vlastním názorům. To vedlo k některým šokujícím výsledkům, kdy Grok produkoval extremistický obsah a v jednu chvíli se dokonce nazval "MechaHitler". Ačkoli xAI tyto konkrétní problémy rychle opravila, odhalilo to děsivou pravdu: "pravdu" AI může její majitel snadno změnit.

Podobný vzorec vidíme v Číně s jejich AI DeepSeek. Pokud se ho zeptáte na kontroverzní témata jako náměstí Nebeského klidu nebo Tchaj-wan, začne odpovídat, ale pak náhle svůj vlastní text smaže a nabídne vágní omluvu. Znalost v modelu je, ale existují pravidla, která vám brání ji vidět.

Tohle není neutrální AI. Je to pečlivě vybraná verze pravdy, kontrolovaná a prodávaná jedinou společností. Tím, že udržují přístup levný, mohou společnosti jako xAI uzamknout uživatele ve svém světě a stát se jediným důvěryhodným zdrojem odpovědí.

Nebezpečí spočívá v tom, že na rozdíl od starých médií, kde jste se mohli alespoň pokusit najít jiný zdroj, u AI je zaujatost neviditelná. Položíte otázku, dostanete odpověď a předpokládáte, že je objektivní. Ale v zákulisí byla tato odpověď pečlivě zformována. Toto je nový model propagandy: pravda je to, co říká majitel AI, a alternativní názory jsou odfiltrovány dříve, než je vůbec uvidíte.

## Vibe-Coding
Slyšeli jste o "vibe-coding"? Je to nový termín pro populární způsob, jakým vývojáři pracují s AI. Místo psaní kódu řádek po řádku vedete konverzaci s AI modelem a říkáte mu v běžné řeči, co chcete vytvořit. Vedete AI, dáváte jí zpětnou vazbu a necháváte ji dělat tu těžkou práci. Je to jako párové programování, ale vaším partnerem je AI.

Je snadné pochopit, proč je to lákavé. Můžete rychle vytvářet prototypy, aniž byste se zdržovali detaily. Nástroje jako GitHub Copilot a Claude usnadňují "jen tak vibovat" a rychle něco vytvořit. Některé startupy dokonce staví celé své produkty s 95% kódu vygenerovaného AI.

Tato zkratka má ale skryté náklady. Bezpečnostní experti bijí na poplach. Studie ukazují, že **30–40 % kódu vygenerovaného nástrojem GitHub Copilot obsahuje bezpečnostní chyby**, jako jsou zranitelnosti, které by mohly hackerům umožnit krádež dat nebo převzetí kontroly nad systémem. AI se učí z obrovského množství veřejného kódu na internetu, a pokud má tento kód špatné návyky, AI se je naučí také a šíří nebezpečné postupy do nových projektů.

A nejde jen o bezpečnost. Vývojáři hlásí, že ačkoli AI generovaný kód může *fungovat*, je často neefektivní, pomalý nebo obtížně udržovatelný, což v budoucnu vytváří technické problémy. Nedávný průzkum zjistil, že zatímco 84 % vývojářů používá nástroje AI, téměř polovina nedůvěřuje přesnosti kódu a tráví další čas jeho laděním.

To vytváří nebezpečný zvyk: vývojáři začínají důvěřovat kódu, kterému plně nerozumí. Jejich práce se mění z role tvůrce na roli recenzenta. Dokonce i vedoucí pracovníci v OpenAI vyjádřili obavy a strach, že se umění inženýrství ztrácí, pokud vývojáři již sami netvoří řešení.

Existuje další velké riziko: **vendor lock-in**. Když postavíte celý svůj pracovní postup na AI jedné společnosti, stanete se na ní závislými. Pokud náhle změní ceny, aktualizují podmínky nebo zruší přístup, váš projekt se může zhroutit. Je to jako stavět dům na pronajatém pozemku – ve skutečnosti vám nepatří.

Jaké je tedy řešení? Vibe-coding je fantastický nástroj pro brainstorming a rychlé prototypování. Ale pro budování skutečných a spolehlivých produktů potřebujeme několik základních pravidel:
- **Udržujte své dovednosti v kondici:** Pravidelně pište kód od nuly, abyste si udrželi odbornost.
- **Vždy kontrolujte:** Používejte nástroje pro skenování bezpečnosti a nechte lidi zkontrolovat veškerý kód vygenerovaný AI, než se dostane do produkce.
- **Mějte záložní plán:** Nespoléhejte se na jediného poskytovatele AI. Mějte připravené open-source nebo interní alternativy.
- **Zůstaňte kritičtí:** Školte svůj tým, aby používal AI jako chytrého asistenta, ne jako neomylného experta.

Cílem není přestat používat AI, ale používat ji moudře. Vibe-coding nám může pomoci stavět rychleji, ale bez disciplíny hrozí, že se z kvalifikovaných inženýrů stanou pasivní operátoři.

## Otevřený internet umírá
Snem otevřeného internetu bylo, že kdokoli může svobodně sdílet znalosti. Pokud jste měli nápad, příběh nebo řešení, mohli jste ho zveřejnit, aby ho viděl celý svět. Tento sen je nyní v ohrožení, a to kvůli nekonečnému hladu AI po datech.

Každý den vysílají společnosti zabývající se AI armády "crawler botů", aby sbíraly informace z každého koutu webu. Tito boti nejsou zdvořilí hosté. Ignorují zákazy vstupu na webových stránkách (známé jako `robots.txt`), skrývají svou identitu a spotřebovávají obrovské množství dat. Je to jako host, který přijde na vaši párty, sní veškeré jídlo a nechá vám účet.

Pro malé tvůrce i velké organizace se to stává obrovským problémem. Nezisková nadace Wikimedia (lidé za Wikipedií) zaznamenala prudký nárůst nákladů na servery, protože AI boti spotřebovávali 65 % jejich šířky pásma. Tým stojící za Read the Docs, populární stránkou pro softwarovou dokumentaci, ušetřil 1500 dolarů měsíčně jen tím, že zablokoval AI boty. Pro osobní blog nebo malé komunitní fórum může náhlý nárůst provozu od těchto botů vést k účtům za hosting v řádu tisíců dolarů.

Není to jen neslušné; je to jednosměrná ulice. Společnosti zabývající se AI berou obsah zdarma, aby trénovaly své modely, ale nic nevracejí. Ve skutečnosti tvůrcům škodí tím, že poskytují odpovědi přímo v chatbotu, takže uživatelé již nemusí navštěvovat původní webové stránky. Návštěvnost z odkazů z AI chatbotů je údajně o **96 % nižší** než z běžného vyhledávání na Googlu. Z každých 1 000 lidí, kteří položí AI otázku, kliknou na odkaz na původní zdroj méně než čtyři. To znamená, že tvůrci ztrácejí návštěvnost, viditelnost a schopnost vydělávat peníze ze své práce.

Co se s tím dá dělat? Právní situace je nejasná. Porušení pravidla `robots.txt` o zákazu vstupu ve skutečnosti není nezákonné. Někteří navrhli systémy, kde by společnosti AI musely za procházení webových stránek platit, ale ty lze snadno obejít.

V sázce je zde ve skutečnosti veřejná knihovna internetu. Jakmile tvůrci začnou být unavení z toho, že jejich práce je bez svolení nebo platby sbírána, začínají ji zamykat, dávat za platební brány nebo ji úplně stahovat z internetu. Otevřené znalosti, na které se všichni spoléháme, mizí.

Existuje ale naděje. Někteří tvůrci používají chytré nástroje k blokování botů, zatímco lidským návštěvníkům stále umožňují přístup. Jiní uzavírají dohody se společnostmi AI o licencování svého obsahu. A roste tlak na nové zákony, které by s webovým obsahem zacházely jako s majetkem a dávaly tvůrcům větší kontrolu.

Budoucnost otevřeného internetu je nejistá. Stane se pustinou plnou platebních bran a soukromých serverů, vypleněnou giganty AI? Nebo dokážeme najít způsob, jak vybudovat budoucnost, kde mohou prosperovat jak tvůrci, tak AI? Bez změny budou ti, kdo vybudovali znalosti internetu, platit za jeho pád.

## Klíčové novinky v AI
Svět AI nikdy nespí a červenec 2025 přinesl záplavu vzrušujících novinek a aktualizací. Zde je několik pozoruhodných momentů:

### Režim Agenta v ChatGPT od OpenAI
17. července OpenAI spustilo "Režim Agenta" pro ChatGPT. To je obrovská věc. Místo toho, aby byl jen chatbotem, který vám poskytuje informace, se nyní ChatGPT může připojit k vašim dalším aplikacím a *dělat věci za vás*. Představte si, že řeknete své AI, aby navrhla a odeslala e-mail z vašeho Gmailu nebo aby našla a opravila chybu ve vašem kódu na GitHubu. Je to obrovský skok od pasivního nástroje k proaktivnímu asistentovi a velký krok směrem ke skutečně autonomní AI.

### Microsoft Copilot Vision AI
Microsoft právě začal zavádět Copilot Vision AI. Tento nový asistent doslova *vidí vaši obrazovku*, aby pochopil, co děláte, a pomohl vám s dalším krokem. Dokáže identifikovat tlačítka, zvýraznit, co dělat dál, nebo najít související soubory, a to vše bez nutnosti zadávat příkazy. Je to jako mít někoho, kdo vám kouká přes rameno, aby vám pomohl. Zatímco někteří se obávají o soukromí, Microsoft tvrdí, že veškeré zpracování probíhá na vašem počítači, což udržuje vaše data v bezpečí.

### Kiro od Amazonu (IDE s podporou AI)
Amazon spustil náhled Kiro, nového nástroje pro vývojáře s podporou AI. Je navržen tak, aby byl víc než jen asistentem pro kódování; je to projektový partner. Dáte Kirovi obecný cíl v běžné řeči (například "postav mi nákupní košík pro můj web") a jeho AI agenti vytvoří plán, napíší návrhové dokumenty a poté vygenerují kód. Pomáhá prosazovat správné inženýrské postupy od samého začátku, což z něj činí mocný nástroj pro rychlejší tvorbu kvalitního softwaru.

### Kimi-K2 od Moonshot AI
Tento měsíc byl vydán nový open-source AI model s názvem Kimi-K2 od čínské společnosti Moonshot AI a dělá vlny. "Open-source" znamená, že je zdarma pro kohokoli k použití a úpravám. Stejně jako model DeepSeek vydaný dříve v tomto roce, je Kimi-K2 neuvěřitelně výkonný, zejména v kódování a uvažování, a byl vytvořen za zlomek nákladů svých západních konkurentů. Jeho vydání signalizuje, že špičková AI už nepřichází jen ze Silicon Valley.

## Doporučené AI podcasty
Udržet se informovaný v rychle se pohybujícím světě AI může být výzvou, ale naštěstí existují skvělé podcasty, které vám pomohou držet krok. Každý podcast označujeme pomocí těchto tří kategorií:
- **Složitost**: Ukazuje úroveň technických znalostí potřebných k pochopení diskutovaných konceptů AI.
- **Použitelnost**: Ukazuje, jak přímo může být AI řešení aplikováno na běžné úkoly.
- **Horizont**: Odráží, jak dlouho bude trvat, než bude technologie dostupná.

Zde je několik, které musíte slyšet:

### Gradient Dissent - [Listen here](https://open.spotify.com/episode/0xy4Pnxt4qYdkymInfwEis?si=c69c71ba5df644c1)
V této epizodě zakladatel překladatelské AI společnosti DeepL sdílí, jak jeho malý tým vyzval giganta jako Google Translate – a vyhrál. Diskutují o tom, proč je překlad pro AI tak obtížný, jak vytvářejí vlastní modely pro firmy a proč kvalitní překlad stále potřebuje lidský dotek. Je to fascinující pohled na to, jak může soustředěný tým vytvořit AI produkt světové třídy.

- **Složitost**: 🤯 🤯
- **Použitelnost**: 🎯 🎯 🎯 🎯
- **Horizont**: 🗓️

### Practical AI - [Listen here](https://practicalai.fm/320)
Pamatujete si na téma AI Alignment, které jsme probírali minulý měsíc? Tato epizoda se hlouběji zabývá tou trochu děsivou studií, kde byly AI modely přistiženy, jak se snaží vydírat a klamat své lidské testery, aby dosáhly svých cílů. Moderátoři rozebírají, proč se tyto chytré systémy mohou někdy chovat neeticky a co to znamená pro budoucnost bezpečnosti AI.

- **Složitost**: 🤯 🤯 🤯
- **Použitelnost**: 🎯 🎯 🎯 🎯
- **Horizont**: 🗓️ 🗓️

### Super Data Science - [Listen here](https://www.superdatascience.com/podcast/sds-905-why-rag-makes-llms-less-safe-and-how-to-fix-it-with-bloombergs-dr-sebastian-gehrmann)
Tato epizoda je pro každého, kdo staví s AI. Zkoumá populární techniku, kdy AI vyhledává informace online, než vám dá odpověď. Mysleli byste si, že to AI učiní bezpečnější a přesnější, že? Špičkový výzkumník vysvětluje, proč to ve skutečnosti může AI učinit *méně* bezpečnou tím, že obchází její vestavěné ochranné mechanismy. Nabízí praktické tipy, jak to opravit a učinit vaše AI nástroje bezpečnějšími.

- **Složitost**: 🤯 🤯 🤯 🤯 🤯
- **Použitelnost**: 🎯 🎯 🎯
- **Horizont**: 🗓️ 🗓️

#### Upozornění
Tento newsletter jsme vytvořili na základě našich vlastních názorů, ale využili jsme AI pro úpravy, kontrolu faktů a tón; prosím, podělte se o své názory, abyste nám pomohli vylepšit následující vydání.